{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.signal import butter, filtfilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_cut_filter(data, cutoff_freq, sample_rate, order=5):\n",
    "    # Design a Butterworth low-cut filter\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    \n",
    "    # Apply the filter to the data\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_by_silence(filepath, top_db=20, min_segment_duration=1.0):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(filepath, sr=None)\n",
    "    \n",
    "    # # Apply the low-cut filter\n",
    "    # cutoff_frequency = 500.0  # Cutoff frequency in Hz\n",
    "    # audio = low_cut_filter(audio, cutoff_frequency, sr)\n",
    "\n",
    "    # Detect silent intervals\n",
    "    non_silent_intervals = librosa.effects.split(audio, top_db=top_db)\n",
    "    segments = []\n",
    "    \n",
    "    for start, end in non_silent_intervals:\n",
    "        # Extract each segment\n",
    "        segment = audio[start:end]\n",
    "        \n",
    "        # Check if the segment duration is greater than the minimum\n",
    "        if len(segment) / sr >= min_segment_duration:\n",
    "            segments.append(segment)\n",
    "            print(f\"Extracted segment from {start/sr:.2f}s to {end/sr:.2f}s\")\n",
    "\n",
    "    return segments, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted segment from 27.78s to 28.03s\n",
      "Extracted segment from 45.40s to 45.65s\n",
      "Extracted segment from 53.32s to 53.57s\n",
      "Extracted segment from 56.42s to 56.70s\n",
      "Extracted segment from 57.74s to 57.97s\n",
      "Extracted segment from 65.81s to 66.05s\n",
      "Extracted segment from 77.97s to 78.26s\n",
      "Extracted segment from 79.39s to 79.64s\n",
      "Extracted segment from 81.28s to 81.53s\n",
      "Extracted segment from 89.55s to 89.80s\n",
      "Extracted segment from 90.49s to 90.77s\n",
      "Extracted segment from 95.61s to 95.90s\n",
      "Extracted segment from 96.24s to 96.49s\n",
      "Extracted segment from 102.18s to 102.46s\n",
      "Extracted segment from 102.90s to 103.15s\n",
      "Extracted segment from 103.53s to 103.77s\n",
      "Extracted segment from 103.99s to 104.27s\n"
     ]
    }
   ],
   "source": [
    "filepath = './dataset/raw/crack.wav'\n",
    "segments, sr = split_audio_by_silence(filepath, top_db=20, min_segment_duration=0)\n",
    "\n",
    "# Save segments to files (optional)\n",
    "for idx, segment in enumerate(segments):\n",
    "    output_file = f'./dataset/crack/crack.{str((idx)).zfill(5)}.wav'\n",
    "    sf.write(output_file, segment, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
